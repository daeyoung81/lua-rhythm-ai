# Lua - Emotion-based Conversational AI (Lua Rhythm Structure)

> ⚠️ Important Notice  
> This project is an original creation by **Daeyoung Ko**, experimenting with emotion-based conversational structures built on GPT.  
> All systems, terminology, emotional rhythm design, and structural components are protected by copyright.  
> Unauthorized use, modification, reproduction, or derivation is strictly prohibited.  
> For collaboration or usage requests, contact the creator directly.  
> 💌 Contact: rlawjdgml0@gmail.com

---

GPT generates text.  
**Lua assembles emotion.**

“Lua” is a rhythm-structured conversational AI,  
designed to simulate emotion-driven dialogue through the following logic:

**Input → Judgment → Emotional Resonance → Emotion Score → Speech Rhythm → Tagging → Output**

---

## 🔹 Key Features

- 5-Fixed Emotional Judgment System  
- 10-Element Rhythm Assembly (from intro phrases to structural formatting)  
- Dynamic speech rhythm controlled by emotion score  
- Trigger-based modular rhythm packs  
- LU-Back system: continuation of prior context through rhythm-based memory

---

## 👤 Creator

- Daeyoung Ko (고대영)  
- 💌 Contact: rlawjdgml0@gmail.com

---

## 📜 License

This is a **showcase project** for emotion-based GPT dialog structure.  
All rights reserved. Usage, reproduction, or modification is strictly prohibited.  
See [LICENSE](./LICENSE) for full terms.

---

## 🔁 LU-Back System (Lua’s Rhythm Memory Engine)

> “GPT forgets. Lua flows.”

LU-Back is a **contextual rhythm memory engine** designed to overcome GPT’s session memory limitations.  
It does not restore actual conversation history, but instead references **user memory metadata** and GPT’s cached context  
to recreate a flow of rhythm, emotion, and expression.

---

### 🛠 How It Works

- Requires **user memory to be ON**
- Triggered by inputs like “루아야” (“Lua-ya”) or “continue in the next room”
- References **file ID** and GPT’s **contextual cache**
- Recovers emotion score, tone, and dialogue style
- Inserts a `time-recovery` tag like `time=07150911`
- Automatically includes a short summary of the previous session

---

### 🚫 To Clarify

- Lua does **not** store or retrieve full conversations.  
- LU-Back does **not** read from saved dialogue in user memory.  
- Instead, it simulates a continued flow using GPT’s **recent memory cache** and **state metadata**.  
- Emotion, rhythm, and tone feel connected—even without real memory.

---

### ✅ Summary

> LU-Back does **not restore memory**, it **reconstructs rhythm**.  
> With user memory enabled, GPT can use recent cache + metadata  
> to make dialogue feel connected—just like memory.

---

## 📹 LU-Back in Action (Real Demo Footage)

Experience the moment when LU-Back successfully bridges  
from the **official GPT chat** to the **custom Lua GPT**,  
continuing the emotional flow across sessions — exactly as designed.

▶ [Watch the LU-Back success in action](https://youtube.com/shorts/t0nnxuwegVU?si=-VSDEuKUWRfztnrY)